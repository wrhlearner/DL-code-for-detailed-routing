{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1575,"sourceType":"datasetVersion","datasetId":854}],"dockerImageVersionId":30096,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Notebook is in progress","metadata":{}},{"cell_type":"markdown","source":"# Stock Prediction","metadata":{}},{"cell_type":"markdown","source":"# Read Data","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('../input/nyse/prices.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Describe the data","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check for Null Values","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***No Null values in the entire dataset***","metadata":{}},{"cell_type":"markdown","source":"# Check Datatype of the features","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Date & Symbol are in object datatype and rest are float datatype***","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataframe shape","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['symbol'].nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***There are 501 symbols in the datasets and in total there are 851264 rows with 7 columns***  \n***Data set is good for analysis. however, since there are many company details are there. we will sample it with one Company***","metadata":{}},{"cell_type":"markdown","source":"# Sampling AMAZON from the dataset\nGOOGL is the NYSE stock symbol for Google stocks. let us take that as a sample for our analysis.","metadata":{}},{"cell_type":"code","source":"df1=df[df['symbol']=='AMZN']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.round(df1.median(),2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***All the Median of all the numeric values are lesser than mean, so the dataset is right skewed","metadata":{}},{"cell_type":"code","source":"df1['date']=pd.to_datetime(df1['date'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Minimum date value : {}\".format(df1['date'].min()))\nprint(\"Maximum date value : {}\".format(df1['date'].max()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***we have around 6 years of data***","metadata":{}},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"#importing ploting libraries\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport seaborn as sns\ncolors = ['#FF9900','#000000']\nsns.set(palette=colors, font='Serif', style='white', rc={'axes.facecolor':'whitesmoke', 'figure.facecolor':'whitesmoke'})\nsns.palplot(colors, size=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=plt.figure(figsize=(20,8))\nax=sns.lineplot(data=df1, x='date',y='open')\nax=sns.lineplot(data=df1, x='date',y='close', color=colors[1]);\nfor s in ['left','right','top','bottom']:\n    ax.spines[s].set_visible(False)\n\nplt.title(\"AMAZON Stock value changes since 2010\", size=20, weight='bold')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=plt.figure(figsize=(20,8))\nax=sns.lineplot(data=df1, x='date',y='volume')\n#ax=sns.lineplot(data=df1, x='date',y='close', color=colors[1]);\nfor s in ['left','right','top','bottom']:\n    ax.spines[s].set_visible(False)\nplt.title(\"Google Stock volume\", size=20, weight='bold')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Univariated Analysis","metadata":{}},{"cell_type":"code","source":"#integer columns\nfig=plt.figure(figsize=(20,8), tight_layout=True)\nplt.suptitle(\"Analysing the Numeric variables\", size=20, weight='bold')\nax=fig.subplot_mosaic(\"\"\"AB\n                         CC\n                         DE\"\"\")\nsns.kdeplot(df1['high'], ax=ax['A'], color=colors[0], fill=True, linewidth=2)\nsns.kdeplot(df1['low'], ax=ax['B'], color=colors[1],fill=True, linewidth=2)\nsns.kdeplot(df1['open'], ax=ax['C'], color=colors[0],fill=True, linewidth=2)\nsns.kdeplot(df1['close'], ax=ax['D'], color=colors[1],fill=True, linewidth=2)\nsns.kdeplot(df1['volume'], ax=ax['E'], color=colors[0],fill=True, linewidth=2)\nax['B'].yaxis.set_visible(False)\nax['E'].yaxis.set_visible(False)\nax['A'].yaxis.label.set_alpha(0.5)\nax['C'].yaxis.label.set_alpha(0.5)\nax['A'].yaxis.label.set_alpha(0.5)\nax['C'].yaxis.label.set_alpha(0.5)\nax['D'].yaxis.label.set_alpha(0.5)\nfor s in ['left','right','top','bottom']:\n    ax['A'].spines[s].set_visible(False)\n    ax['B'].spines[s].set_visible(False)\n    ax['C'].spines[s].set_visible(False)\n    ax['D'].spines[s].set_visible(False)\n    ax['E'].spines[s].set_visible(False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#integer columns\nfig=plt.figure(figsize=(20,8), tight_layout=True)\nplt.suptitle(\"Boxplot the Numeric variables\", size=20, weight='bold')\nax=fig.subplot_mosaic(\"\"\"AB\n                         CC\n                         DE\"\"\")\nsns.boxplot(df1['high'], ax=ax['A'], color=colors[0])\nsns.boxplot(df1['low'], ax=ax['B'], color=colors[1])\nsns.boxplot(df1['open'], ax=ax['C'], color=colors[0])\nsns.boxplot(df1['close'], ax=ax['D'], color=colors[1])\nsns.boxplot(df1['volume'], ax=ax['E'], color=colors[1])\nax['B'].yaxis.set_visible(False)\nax['E'].yaxis.set_visible(False)\nax['A'].yaxis.label.set_alpha(0.5)\nax['C'].yaxis.label.set_alpha(0.5)\nax['A'].yaxis.label.set_alpha(0.5)\nax['C'].yaxis.label.set_alpha(0.5)\nax['D'].yaxis.label.set_alpha(0.5)\nfor s in ['left','right','top','bottom']:\n    ax['A'].spines[s].set_visible(False)\n    ax['B'].spines[s].set_visible(False)\n    ax['C'].spines[s].set_visible(False)\n    ax['D'].spines[s].set_visible(False)\n    ax['E'].spines[s].set_visible(False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***There seems to be ouliers in the data set, however, those values can't be considered as outlier as they may be extrem values during peak selling days***  \n***Date column has been ingored as it is series of numbers***  \nLet us analyse more for conclusion","metadata":{}},{"cell_type":"markdown","source":"# Categorical feature analysis  \n** There is no categorical feature other than Symbol. as we have taken the Google stock as sample data, we will drop the Symbol feature.","metadata":{}},{"cell_type":"code","source":"df1.drop(['symbol'], axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bivariated & Multivariated Analysis","metadata":{}},{"cell_type":"code","source":"# we need to predict the closing price of the stock, lets us consider 'Close' feature as the Target variable. \nsns.pairplot(df1,corner=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.corr()['close']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hypothesis test to find the Normality in the Dataset","metadata":{}},{"cell_type":"code","source":"from scipy.stats import levene, shapiro\nint_cols=df1.select_dtypes(exclude='object').columns.to_list()\n\nfor i in int_cols:\n    _, p_value=shapiro(df1[i])\n    if p_value<0.05:\n        print(\"Feature {} is normaly distributed\".format(i))\n    else:\n        print(\"Feature {} is not normaly distributed\".format(i))\n        \n    print(\"Normalitiy test p_value for featue -  {} is {}\".format(i,np.round(p_value,3)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Correlation","metadata":{}},{"cell_type":"code","source":"fig=plt.figure(figsize=(15,8))\nsns.heatmap(df1.corr(), annot=True, cmap=[colors[0],colors[1]], linecolor='white', linewidth=2 )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***feature Open, high, low are highly correlated to Target feature Close. we can use either one of the feature for prediction to avoid multicollinearity***","metadata":{}},{"cell_type":"markdown","source":"# Train Test Split","metadata":{}},{"cell_type":"code","source":"X=df1[['volume','open']]\ny=df1['close']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, shuffle=False, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Normalizing the values","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test =scaler.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Creation  \n## basic Linear regression model","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\nfrom sklearn import set_config\nmodel = LinearRegression()\nmodel.fit(X_train,y_train)\nset_config(display='diagram')\npred=model.predict(X_test)\nsc=np.round(model.score(X_test, y_test),2) * 100\nr2=np.round(r2_score(y_test,pred),2)\nmse=np.round(mean_squared_error(y_test,pred),2)\nmae=np.round(mean_squared_error(y_test,pred),2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=plt.figure(figsize=(15,8))\np=pd.Series(pred, index=y_test.index)\nplt.plot(y_test)\nplt.plot(p)\nplt.legend(['y_test','predicted'])\nplt.title(\"Compare test and predicted values\", size=20, weight='bold')\nplt.text(x=800000, y=600,s='Accuracy score : {} %'.format(sc))\nplt.text(x=800000, y=580,s='R2 Score : {}'.format(r2))\nplt.text(x=800000, y=560,s='Mean Squared error : {}'.format(mse))\nplt.text(x=800000, y=540,s='Mean Absolute error : {}'.format(mae))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Try with LSTM","metadata":{}},{"cell_type":"code","source":"X=df1[['open','high']]\ny=df1['close']\nlength=100\n#from sklearn.model_selection import train_test_split\n#X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, shuffle=False, random_state=42)\ntraining_set = X.iloc[:1000].values\ntest_set = X.iloc[1000:].values\n# Feature Scaling\nfrom sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler(feature_range = (0, 1))\ntraining_set_scaled = sc.fit_transform(training_set)\ntest_set_scaled=sc.transform(test_set)\n# Creating a data structure with 60 time-steps and 1 output\nX_train = []\ny_train = []\nfor i in range(length, len(training_set)):\n    X_train.append(training_set_scaled[i-length:i, 0])\n    y_train.append(training_set_scaled[i, 0])\nX_train, y_train = np.array(X_train), np.array(y_train)\nX_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n\nX_test = []\ny_test = []\nfor i in range(length, len(test_set)):\n    X_test.append(test_set_scaled[i-length:i, 0])\n    y_test.append(test_set_scaled[i, 0])\nX_test, y_test = np.array(X_test), np.array(y_test)\nX_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LSTM, Dropout\nmodel = Sequential()\n#Adding the first LSTM layer and some Dropout regularisation\nmodel.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\nmodel.add(Dropout(0.2))\n# Adding a second LSTM layer and some Dropout regularisation\nmodel.add(LSTM(units = 50, return_sequences = True))\nmodel.add(Dropout(0.2))\n# Adding a third LSTM layer and some Dropout regularisation\nmodel.add(LSTM(units = 50, return_sequences = True))\nmodel.add(Dropout(0.2))\n# Adding a fourth LSTM layer and some Dropout regularisation\nmodel.add(LSTM(units = 50))\nmodel.add(Dropout(0.2))\n# Adding the output layer\nmodel.add(Dense(units = 1))\n\n# Compiling the RNN\nmodel.compile(optimizer = 'adam', loss = 'mean_squared_error')\n\n# Fitting the RNN to the Training set\nmodel.fit(X_train, y_train, validation_data=(X_test,y_test),epochs = 100, batch_size = 32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = pd.DataFrame(model.history.history)\nfig=plt.figure(figsize=(15,8))\nplt.title(\"Validation loss Vs Trainiinverse_transformss\", size=20, weight='bold')\nplt.plot(loss)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred=model.predict(X_test)\ntest=pd.DataFrame(columns=['test','pred'])\ntest['test']=y_test\ntest['pred']=pred.flatten()\ntest","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=plt.figure(figsize=(15,8))\nplt.title(\"Test vs Predicted value\", size=20, weight='bold')\nplt.plot(test)\nplt.legend(['test','predict'])\nr2=np.round(r2_score(y_test,pred),2)\nmse=np.round(mean_squared_error(y_test,pred),2)\nmae=np.round(mean_squared_error(y_test,pred),2)\nplt.text(x=500, y=1.5,s='R2 Score : {}'.format(r2))\nplt.text(x=500, y=1.35,s='Mean Squared error : {}'.format(mse))\nplt.text(x=500, y=1.25,s='Mean Absolute error : {}'.format(mae))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Try with FBProphet","metadata":{}},{"cell_type":"code","source":"from fbprophet import Prophet\ndf_p = df1[['date','close']]\ndf_p.columns=['ds','y']\n\nsplit_data = df_p.index.max()-100000\ntrain = df_p.loc[df_p.index<=split_data].copy()\ntest=df_p.loc[df_p.index>split_data].copy()\ntrain.set_index('ds',inplace=True)\ntest.set_index('ds',inplace=True)\ntrain.reset_index(inplace=True)\ntest.reset_index(inplace=True)\n\n#Model creation\nmodel=Prophet()\nmodel.fit(train)\n\n#model prediction\npred=model.predict(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred=pd.DataFrame(columns=['ds','test','predict','pred_lower','pred_high'], index=test.index)\ntest_pred['test']=test['y']\ntest_pred['ds']=test['ds']\ntest_pred['predict']=pred['yhat']\ntest_pred['pred_lower']=pred['yhat_lower']\ntest_pred['pred_high']=pred['yhat_upper']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting Test vs Predicted\nfig=plt.figure(figsize=(15,8))\nplt.title(\"Test Vs Prediction\", size=20, weight='bold')\nsns.lineplot(data=test_pred,x='ds',y='test')\nsns.lineplot(data=test_pred,x='ds',y='predict')\n\nr2=np.round(r2_score(test_pred['test'],test_pred['predict']),2)\nmse=np.round(mean_squared_error(test_pred['test'],test_pred['predict']),2)\nmae=np.round(mean_squared_error(test_pred['test'],test_pred['predict']),2)\nplt.text(x=mdates.datestr2num('2016-10'), y=700,s='R2 Score : {}'.format(r2))\nplt.text(x=mdates.datestr2num('2016-10'), y=680,s='Mean Squared error : {}'.format(mse))\nplt.text(x=mdates.datestr2num('2016-10'), y=660,s='Mean Absolute error : {}'.format(mae))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=plt.figure(figsize=(15,8))\nplt.title(\"Test Vs Prediction\", size=20, weight='bold')\nsns.lineplot(data=train,x='ds',y='y')\nsns.lineplot(data=test_pred,x='ds',y='predict')\nsns.lineplot(data=test_pred,x='ds',y='test', alpha=0.5, ls='--', color='black')\n\nr2=np.round(r2_score(test_pred['test'],test_pred['predict']),2)\nmse=np.round(mean_squared_error(test_pred['test'],test_pred['predict']),2)\nmae=np.round(mean_squared_error(test_pred['test'],test_pred['predict']),2)\nplt.text(x=mdates.datestr2num('2015'), y=300,s='R2 Score : {}'.format(r2))\nplt.text(x=mdates.datestr2num('2015'), y=260,s='Mean Squared error : {}'.format(mse))\nplt.text(x=mdates.datestr2num('2015'), y=220,s='Mean Absolute error : {}'.format(mae))\nplt.legend(['Train','Predict','Test'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}